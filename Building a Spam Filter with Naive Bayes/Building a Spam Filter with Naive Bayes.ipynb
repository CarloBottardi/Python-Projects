{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Spam Filter with Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To classify messages as spam or non-spam, the computer:\n",
    "\n",
    "- Learns how humans classify messages.\n",
    "- Uses that human knowledge to estimate probabilities for new messages — probabilities for spam and non-spam.\n",
    "- Classifies a new message based on these probability values and if the probability for spam is greater, then it classifies the message as spam. Otherwise, it classifies it as non-spam (if the two probability values are equal, then we may need a human to classify the message).\n",
    "\n",
    "So the first task is to \"teach\" the computer how to classify messages. To do that, I'll use the multinomial Naive Bayes algorithm along with a dataset of 5,572 SMS messages that are already classified by humans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "spam_database=pd.read_csv(\"SMSSpamCollection\", sep='\\t', header=None, names=['Label', 'SMS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Label                                                SMS\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "print(spam_database.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ham__ means non-spam. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    }
   ],
   "source": [
    "print(spam_database.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747\n"
     ]
    }
   ],
   "source": [
    "spam_sms=spam_database[spam_database[\"Label\"]==\"spam\"]\n",
    "print(spam_sms.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4825\n"
     ]
    }
   ],
   "source": [
    "ham_sms=spam_database[spam_database[\"Label\"]==\"ham\"]\n",
    "print(ham_sms.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.406317300789663\n",
      "86.59368269921033\n"
     ]
    }
   ],
   "source": [
    "n_sms_tot=5572\n",
    "n_spam=747\n",
    "n_ham=4825\n",
    "p_spam=n_spam/n_sms_tot\n",
    "p_ham=n_ham/n_sms_tot\n",
    "print(p_spam*100)\n",
    "print(p_ham*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 87% of the messages are ham (non-spam), and the remaining 13% are spam.\n",
    "\n",
    "Once our spam filter is done, we'll need to test how good it is with classifying new messages. To test the spam filter, I'm first going to split our dataset into two categories:\n",
    "\n",
    "- A training set, which we'll use to \"train\" the computer how to classify messages.\n",
    "- A test set, which we'll use to test how good the spam filter is with classifying new messages.\n",
    "\n",
    "It's better to keep 80% of the dataset for training, and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Label                                                SMS\n",
      "1078   ham                       Yep, by the pretty sculpture\n",
      "4028   ham      Yes, princess. Are you going to make me moan?\n",
      "958    ham                         Welp apparently he retired\n",
      "4642   ham                                            Havent.\n",
      "4674   ham  I forgot 2 ask ü all smth.. There's a card on ...\n",
      "5461   ham  Ok i thk i got it. Then u wan me 2 come now or...\n",
      "4210   ham  I want kfc its Tuesday. Only buy 2 meals ONLY ...\n",
      "4216   ham                         No dear i was sleeping :-P\n",
      "1603   ham                          Ok pa. Nothing problem:-)\n",
      "1504   ham                    Ill be there on  &lt;#&gt;  ok.\n"
     ]
    }
   ],
   "source": [
    "rand_spam_database=spam_database.sample(frac=1, random_state=1)\n",
    "print(rand_spam_database.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.67563930013459   13.324360699865412\n",
      "86.17594254937163   13.824057450628368\n"
     ]
    }
   ],
   "source": [
    "training=rand_spam_database.sample(frac=0.8, random_state=1)\n",
    "test=rand_spam_database.sample(frac=0.2, random_state=1)\n",
    "training_ham=training[training[\"Label\"]==\"ham\"].shape[0]\n",
    "training_spam=training[training[\"Label\"]==\"spam\"].shape[0]\n",
    "test_ham=test[test[\"Label\"]==\"ham\"].shape[0]\n",
    "test_spam=test[test[\"Label\"]==\"spam\"].shape[0]\n",
    "p_training_ham=training_ham/(training_ham+training_spam)\n",
    "p_training_spam=1-p_training_ham\n",
    "p_test_ham=test_ham/(test_ham+test_spam)\n",
    "p_test_spam=1-p_test_ham\n",
    "print(100*p_training_ham, \" \", 100*p_training_spam)\n",
    "print(100*p_test_ham, \" \", 100*p_test_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The samples are representative of the whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Letter Case and Punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll begin the data cleaning process by removing the punctuation and bringing all the words to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3404         good night my dear   sleepwell amp take care\n",
      "4781    sen told that he is going to join his uncle fi...\n",
      "484     thank you baby  i cant wait to taste the real ...\n",
      "502                                  when can ü come out \n",
      "3898                 no  thank you  you ve been wonderful\n",
      "96                      watching telugu movie  wat abt u \n",
      "2177                      get ready to moan and scream   \n",
      "2841    babe     i miiiiiiissssssssss you   i need you...\n",
      "993     up to ü    ü wan come then come lor    but i d...\n",
      "3590    i ve sent my wife your text  after we buy them...\n",
      "Name: SMS, dtype: object\n"
     ]
    }
   ],
   "source": [
    "training[\"SMS\"]=training[\"SMS\"].str.replace(r\"\\W\", \" \").str.lower()\n",
    "print(training[\"SMS\"].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll now move to creating the vocabulary, which in this context means a list with all the unique words in our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary=[]\n",
    "training_2=training.copy()\n",
    "training_2[\"SMS\"]=training_2[\"SMS\"].str.split()\n",
    "training_2.reset_index(inplace=True)\n",
    "for sms in training_2[\"SMS\"]:\n",
    "    for word in sms:\n",
    "        vocabulary.append(word)\n",
    "set_of_words=set(vocabulary)\n",
    "list_of_words=list(set_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Final Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm now going to use the just created vocabulary to make the data transformation we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(training_2['SMS']) for unique_word in list_of_words}\n",
    "\n",
    "for index, sms in enumerate(training_2['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4458, 7712)\n"
     ]
    }
   ],
   "source": [
    "wcps_df = pd.DataFrame(word_counts_per_sms)\n",
    "print(wcps_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4458, 7715)\n"
     ]
    }
   ],
   "source": [
    "training_3=pd.concat([training_2, wcps_df], axis=1)\n",
    "print(training_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['0', '00', '000', '000pes', '008704050406', '0089', '0121',\n",
      "       '01223585236', '01223585334', '0125698789',\n",
      "       ...\n",
      "       'zoe', 'zogtorius', 'zoom', 'zouk', 'èn', 'é', 'ú1', 'ü', '〨ud', '鈥'],\n",
      "      dtype='object', length=7712)\n"
     ]
    }
   ],
   "source": [
    "print(wcps_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index Label                                                SMS  0  00\n",
      "4453    657   ham  [sun, cant, come, to, earth, but, send, luv, a...  0   0\n",
      "4454   4753   ham  [well, boy, am, i, glad, g, wasted, all, night...  0   0\n",
      "4455   1442   ham                       [ya, going, for, restaurant]  0   0\n",
      "4456   2105   ham  [anyway, seriously, hit, me, up, when, you, re...  0   0\n",
      "4457   4585   ham  [noooooooo, please, last, thing, i, need, is, ...  0   0\n"
     ]
    }
   ],
   "source": [
    "print(training_3.iloc[:,:5].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 7715)\n"
     ]
    }
   ],
   "source": [
    "print(training_3[training_3[\"Label\"].isnull()].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [index, Label, SMS, 0, 00, 000, 000pes, 008704050406, 0089, 0121, 01223585236, 01223585334, 0125698789, 02, 0207, 02073162414, 02085076972, 021, 03, 04, 05, 050703, 0578, 06, 07, 07008009200, 07046744435, 07090201529, 07090298926, 07099833605, 07123456789, 0721072, 07732584351, 07734396839, 07742676969, 07753741225, 0776xxxxxxx, 07781482378, 07786200117, 077xxx, 07801543489, 07808, 07808247860, 07808726822, 07821230901, 07880867867, 0789xxxxxxx, 07946746291, 0796xxxxxx, 07973788240, 07xxxxxxxxx, 08, 0800, 08000407165, 08000776320, 08000839402, 08000930705, 08000938767, 08001950382, 08002888812, 08002986030, 08002986906, 08002988890, 08006344447, 0808, 08081263000, 08081560665, 0825, 083, 0844, 08448350055, 0845, 08450542832, 08452810073, 08452810075over18, 0870, 08700435505150p, 08700621170150p, 08701213186, 08701417012, 08701417012150p, 0870141701216, 087016248, 087018728737, 0870241182716, 08702490080, 08702840625, 08704050406, 08704439680, 08704439680ts, 08706091795, 0870737910216yrs, 08707500020, 08707509020, 0870753331018, 08707808226, 08708800282, 08709222922, 0871, 087104711148, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 7715 columns]\n"
     ]
    }
   ],
   "source": [
    "print(training_3[training_3[\"Label\"].isnull()].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4458, 3)\n"
     ]
    }
   ],
   "source": [
    "print(training_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Constants First"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I'm done with data cleaning and have a training set to work with, I can begin creating the spam filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15142\n",
      "57140\n"
     ]
    }
   ],
   "source": [
    "alpha=1\n",
    "N_spam=0\n",
    "N_ham=0\n",
    "training_2_spam=training_2[training_2[\"Label\"]==\"spam\"]\n",
    "training_2_ham=training_2[training_2[\"Label\"]==\"ham\"]\n",
    "for li in training_2_spam[\"SMS\"]:\n",
    "    N_spam+=len(li)\n",
    "for li in training_2_ham[\"SMS\"]:\n",
    "    N_ham+=len(li)\n",
    "print(N_spam)\n",
    "print(N_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7712\n"
     ]
    }
   ],
   "source": [
    "N_vocabulary=len(list_of_words)\n",
    "print(N_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability values that P(wi|Spam) and P(wi|Ham) will take are called parameters.\n",
    "The fact that I calculate so many values before even beginning the classification of new messages makes the Naive Bayes algorithm very fast (especially compared to other algorithms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_spam={}\n",
    "for word in list_of_words:\n",
    "    dict_spam[word]=0\n",
    "dict_ham={}\n",
    "for word in list_of_words:\n",
    "    dict_ham[word]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_3_spam=training_3[training_3[\"Label\"]==\"spam\"]\n",
    "training_3_ham=training_3[training_3[\"Label\"]==\"ham\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in list_of_words:\n",
    "    N_word_spam=training_3_spam[word].sum()\n",
    "    parameter_spam=(N_word_spam+alpha)/(N_spam+alpha*N_vocabulary)\n",
    "    dict_spam[word]=parameter_spam\n",
    "    N_word_ham=training_3_ham[word].sum()\n",
    "    parameter_ham=(N_word_ham+alpha)/(N_ham+alpha*N_vocabulary)\n",
    "    dict_ham[word]=parameter_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_spam = len(training_3_spam) / len(training_3)\n",
    "p_ham = len(training_3_ham) / len(training_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13324360699865412\n",
      "0.8667563930013459\n"
     ]
    }
   ],
   "source": [
    "print(p_spam)\n",
    "print(p_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying a New Message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all our parameters calculated, I can start creating the spam filter. The spam filter can be understood as a function that:\n",
    "\n",
    "- Takes in as input a new message (w1, w2, ..., wn).\n",
    "- Calculates P(Spam|w1, w2, ..., wn) and P(Ham|w1, w2, ..., wn).\n",
    "- Compares the values of P(Spam|w1, w2, ..., wn) and P(Ham|w1, w2, ..., wn), and:\n",
    "    - If P(Ham|w1, w2, ..., wn) > P(Spam|w1, w2, ..., wn), then the message is classified as ham.\n",
    "    - If P(Ham|w1, w2, ..., wn) < P(Spam|w1, w2, ..., wn), then the message is classified as spam.\n",
    "    - If P(Ham|w1, w2, ..., wn) = P(Spam|w1, w2, ..., wn), then the algorithm may request human help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    '''    \n",
    "    This is where we calculate:\n",
    "\n",
    "    p_spam_given_message = ?\n",
    "    p_ham_given_message = ?\n",
    "    ''' \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    for word in message:\n",
    "        if word in dict_spam:\n",
    "            p_spam_given_message*=dict_spam[word]\n",
    "        if word in dict_ham:\n",
    "            p_ham_given_message*=dict_ham[word]\n",
    "\n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal probabilities, have a human classify this!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.273700039190484e-25\n",
      "P(Ham|message): 2.6479653658243408e-27\n",
      "Label: Spam\n",
      "P(Spam|message): 1.0782622513413257e-25\n",
      "P(Ham|message): 4.248744927807854e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "example_spam='WINNER!! This is the secret code to unlock the money: C3421.'\n",
    "example_ham=\"Sounds good, Tom, then see u there\"\n",
    "classify(example_spam)\n",
    "classify(example_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the Spam Filter's Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll now try to determine how well the spam filter does on The test set of 1114 messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    '''    \n",
    "    This is where we calculate:\n",
    "\n",
    "    p_spam_given_message = ?\n",
    "    p_ham_given_message = ?\n",
    "    ''' \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    for word in message:\n",
    "        if word in dict_spam:\n",
    "            p_spam_given_message*=dict_spam[word]\n",
    "        if word in dict_ham:\n",
    "            p_ham_given_message*=dict_ham[word]\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Label                                                SMS Predicted\n",
      "3404   ham       Good night my dear.. Sleepwell&amp;Take care       ham\n",
      "4781   ham  Sen told that he is going to join his uncle fi...       ham\n",
      "484    ham  Thank you baby! I cant wait to taste the real ...       ham\n",
      "502    ham                               When can ü come out?       ham\n",
      "3898   ham               No. Thank you. You've been wonderful       ham\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "test[\"Predicted\"]=test[\"SMS\"].apply(classify_test_set)\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.992818671454219\n"
     ]
    }
   ],
   "source": [
    "total=len(test)\n",
    "for index, row in test.iterrows():\n",
    "    if row[\"Label\"]==row[\"Predicted\"]:\n",
    "        correct+=1\n",
    "accuracy=correct/total\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is 99.3%. It's extraordinarily high!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When the Spam Filter was wrong?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the incorrectly classified SMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4703                                           Anytime...\n",
      "5       FreeMsg Hey there darling it's been 3 week's n...\n",
      "1863    The last thing i ever wanted to do was hurt yo...\n",
      "1988                     No calls..messages..missed calls\n",
      "2663    Hello darling how are you today? I would love ...\n",
      "3460    Not heard from U4 a while. Call me now am here...\n",
      "4213    Missed call alert. These numbers called but le...\n",
      "1875    Would you like to see my XXX pics they are so ...\n",
      "Name: SMS, dtype: object\n"
     ]
    }
   ],
   "source": [
    "test_incorrect=test[test[\"Label\"]!=test[\"Predicted\"]]\n",
    "print(test_incorrect[\"SMS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Label                                                SMS  \\\n",
      "4703   ham                                         Anytime...   \n",
      "5     spam  FreeMsg Hey there darling it's been 3 week's n...   \n",
      "1863   ham  The last thing i ever wanted to do was hurt yo...   \n",
      "1988   ham                   No calls..messages..missed calls   \n",
      "2663  spam  Hello darling how are you today? I would love ...   \n",
      "3460  spam  Not heard from U4 a while. Call me now am here...   \n",
      "4213  spam  Missed call alert. These numbers called but le...   \n",
      "1875  spam  Would you like to see my XXX pics they are so ...   \n",
      "\n",
      "                       Predicted  \n",
      "4703                        spam  \n",
      "5                            ham  \n",
      "1863  needs human classification  \n",
      "1988                        spam  \n",
      "2663                         ham  \n",
      "3460                         ham  \n",
      "4213                         ham  \n",
      "1875                         ham  \n"
     ]
    }
   ],
   "source": [
    "print(test_incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anytime...   Label: ham\n",
      "<---------------------------->\n",
      "FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv   Label: spam\n",
      "<---------------------------->\n",
      "The last thing i ever wanted to do was hurt you. And i didn't think it would have. You'd laugh, be embarassed, delete the tag and keep going. But as far as i knew, it wasn't even up. The fact that you even felt like i would do it to hurt you shows you really don't know me at all. It was messy wednesday, but it wasn't bad. The problem i have with it is you HAVE the time to clean it, but you choose not to. You skype, you take pictures, you sleep, you want to go out. I don't mind a few things here and there, but when you don't make the bed, when you throw laundry on top of it, when i can't have a friend in the house because i'm embarassed that there's underwear and bras strewn on the bed, pillows on the floor, that's something else. You used to be good about at least making the bed.   Label: ham\n",
      "<---------------------------->\n",
      "No calls..messages..missed calls   Label: ham\n",
      "<---------------------------->\n",
      "Hello darling how are you today? I would love to have a chat, why dont you tell me what you look like and what you are in to sexy?   Label: spam\n",
      "<---------------------------->\n",
      "Not heard from U4 a while. Call me now am here all night with just my knickers on. Make me beg for it like U did last time 01223585236 XX Luv Nikiyu4.net   Label: spam\n",
      "<---------------------------->\n",
      "Missed call alert. These numbers called but left no message. 07008009200   Label: spam\n",
      "<---------------------------->\n",
      "Would you like to see my XXX pics they are so hot they were nearly banned in the uk!   Label: spam\n",
      "<---------------------------->\n"
     ]
    }
   ],
   "source": [
    "for index, row in test_incorrect.iterrows():\n",
    "    print(row[\"SMS\"], \" \", \"Label:\", row[\"Label\"])\n",
    "    print(\"<---------------------------->\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
